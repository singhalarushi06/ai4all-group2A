# Healthcare Group 2A - AI4ALL Fall 2025
# Detecting GI Diseases

This AI model aims to detect the presence of an autoimmune disease in the digestive tract sooner, leading to the identification of the potential GI disease to allow patients to receive earlier treatment. We explored the idea of biases when looking at sample patient data, learned features in Python to better analyze the data, and much more through the AI4ALL accelerator experience.



## Problem Statement <!--- do not change this line -->
Choosing to do a project in the healthcare track, we were interested in working on some project which could potentially have an impact. Healthcare is such a broad category, but one thing we realized as a trend was the amount of time it takes for people to receive the proper medical attention. We did some research and noticed that autoimmune diseases were one of the issues which took the longest to identify prior to any targeted care. Looking into this, we found that there are over 100 autoimmune diseases. To make this project more feasible, we narrowed our topic down to just the digestive/gastrointestinal tract (covers aroujnd 8-9 autoimmune diseases). With our model, we wanted to identify any patterns to detect the possibility of a patient having an autoimmune disease sooner.


## Key Results <!--- do not change this line -->

(UPDATE IN README.md)
Enumerate the main results of this project in a list and describe them.

*EXAMPLE:*
1. *Recorded over 1,000 unique prompts and their responses generated by ChatGPT*
2. *Identified three biases in ChatGPT's responses*
   - *When prompted about this world event*
   - *When prompted about this field of science*
   - *When prompted about this political party*


## Methodologies <!--- do not change this line -->

(UPDATE IN README.md)

*EXAMPLE:*
*To accomplish this, we utilized the OpenAI API to interact with ChatGPT, and we designed a custom Python script to generate diverse prompts and collect corresponding responses. The data was then processed and analyzed using pandas, enabling us to detect patterns and biases in the AI model's outputs.*
*Engineered a Python script to generate over 1,000 prompts and elicit their responses from ChatGPT, utilizing pandas to collect the data. When prompted for solutions to this specific relevant crisis, nearly 80% of ChatGPT's responses promoted a certain worldview.*


## Data Sources <!--- do not change this line -->
We used 2 datasets from Kaggle, listed below:
   - [Gastrointestinal Disease Dataset](https://www.kaggle.com/datasets/amanik000/gastrointestinal-disease-dataset)
   - [All Autoimmune Disorders](https://www.kaggle.com/datasets/abdullahragheb/all-autoimmune-disorder-10k)

(UPDATE IN README.md)
Include any relevant data sources that were used in your project.

*EXAMPLE:*
*Kaggle Datasets: [Link to Kaggle Dataset](https://www.kaggle.com/datasets)*

## Technologies Used <!--- do not change this line -->

(UPDATE IN README.md)
List the technologies, libraries, and frameworks used in your project.

*EXAMPLE:*
- *Python*
- *pandas*
- *OpenAI API*


## Authors <!--- do not change this line -->
Final Group Members:
- Arushi Singhal
   - Email: arushi.singhal@rutgers.edu
   - LinkedIn: https://www.linkedin.com/in/arushi-singhal1/
   - GitHub: singhalarushi06
- Damilola Babajide
   - LinkedIn: 
   - GitHub:
Mentor:
- Matthew Slomka
